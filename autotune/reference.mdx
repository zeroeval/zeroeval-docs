---
title: "Reference"
description: "Parameters and configuration for ze.prompt"
---

`ze.prompt` creates or fetches versioned prompts from the Prompt Library and returns decorated content for downstream LLM calls.

## Parameters

| Parameter   | Type            | Required | Default | Description |
| ----------- | --------------- | -------- | ------- | ----------- |
| `name`      | string          | yes      | —       | Task name associated with the prompt in the library |
| `content`   | string          | no       | `None`  | Raw prompt content to ensure/create a version by content |
| `from_`     | string          | no       | `None`  | Either `"latest"` or a 64‑char lowercase SHA‑256 content hash to fetch a specific version |
| `from`      | string (alias)  | no       | `None`  | Alias for `from_` (keyword‑only) |
| `variables` | dict            | no       | `None`  | Template variables to render `{{variable}}` tokens in content |

Notes:

- Exactly one of `content` or `from_/from` must be provided.
- `from="latest"` fetches the latest version bound to the task; otherwise `from_` must be a 64‑char hex SHA‑256 hash.

## Behavior

- **content provided**: Computes a normalized SHA‑256 hash, ensures a prompt version exists for `name`, and returns decorated content.
- **from="latest"**: Fetches the latest version for `name` and returns decorated content.
- **from=**`<hash>`: Fetches by content hash for `name` and returns decorated content.

Decoration adds a compact metadata header used by integrations:

- `task`, `prompt_slug`, `prompt_version`, `prompt_version_id`, `variables`, and (when created by content) `content_hash`.

OpenAI integration: when `prompt_version_id` is present, the SDK will automatically patch the `model` parameter to the model bound to that prompt version.

## Return Value

- `str`: Decorated prompt content ready to pass into LLM clients.

## Errors

| Error                  | When |
| ---------------------- | ---- |
| `ValueError`           | Both `content` and `from_` provided, or neither; invalid `from_` (not `"latest"` or 64‑char hex) |
| `PromptRequestError`   | `from_="latest"` but no versions exist for `name` |
| `PromptNotFoundError`  | `from_` is a hash that does not exist for `name` |

## Examples

```python
import zeroeval as ze

# Create/ensure a version by content
system = ze.prompt(
    name="support-triage",
    content="You are a helpful assistant for {{product}}.",
    variables={"product": "Acme"},
)

# Fetch the latest version for this task
system = ze.prompt(name="support-triage", from_="latest")

# Fetch a specific version by content hash
system = ze.prompt(name="support-triage", from_="c6a7...deadbeef...0123")
```


